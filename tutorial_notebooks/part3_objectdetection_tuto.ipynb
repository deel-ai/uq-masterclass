{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e7b3ef",
   "metadata": {},
   "source": [
    "# üñºÔ∏è Part III: Conformal Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd44623d",
   "metadata": {},
   "source": [
    "We are working with an object detection model that is already in production and accessible only through API requests (i.e., we don't have direct access to the model instance). Let's create an instance of the API, which we will use later to query the model and obtain bounding box predictions for images:\n",
    "\n",
    "Let's do conformal object detection on COCO.\n",
    "\n",
    "<div align=center>\n",
    "<img src=\"assets/object_detection_demo.svg\" width=\"800\"> </img>\n",
    "</div>\n",
    "\n",
    "**Links**\n",
    "- [<img src=\"https://github.githubassets.com/images/icons/emoji/octocat.png\" width=20> Github](https://github.com/deel-ai/puncc)\n",
    "- [üìò Documentation](https://deel-ai.github.io/puncc/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d8b81",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Setup  <a class=\"anchor\" id=\"cr-setup\"></a>\n",
    "\n",
    "üêæ For this tutorial, we need to install puncc along with transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc697c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install puncc transformers==4.44.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    os.system(\n",
    "        \"wget https://raw.githubusercontent.com/deel-ai/uq-masterclass/refs/heads/main/tutorial_notebooks/utils.py\"\n",
    "    )\n",
    "    os.system(\"mkdir assets/\")\n",
    "else:\n",
    "    print(\"Not running in Google Colab\")\n",
    "\n",
    "\n",
    "from utils import CocoDataset, ObjectDetectionAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0553572f",
   "metadata": {},
   "source": [
    "We import the general-purpose modules that will be used throughout the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from itertools import compress\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import CocoDataset, ObjectDetectionAPI\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc3cd24",
   "metadata": {},
   "source": [
    "### üíæ Dataset <a class=\"anchor\" id=\"cr-data\"></a>\n",
    "\n",
    "COCO (Common Objects in Context) dataset is a widely used benchmark dataset for object detection. It consists of a large collection of images with detailed annotations, including bounding boxes and object classes. The dataset covers a wide range of object categories and provides a diverse set of images captured in various contexts.\n",
    "\n",
    "The annotations in the dataset provide ground truth information that can be used to train and evaluate the performance of object detection models. In our scenario, we assume the object detection model is already in production and accessible through an API, so there is no need for training samples. Instead, we will focus on data for **calibration**, as part of the conformal prediction procedure, and a **test** dataset to evaluate the performance of uncertainty quantification in object detection.\n",
    "\n",
    "We will use a portion of the 2017 validation data for calibration and the remainder for testing. The annotations configuration file, which provides the image URLs and associated labels, can be downloaded from the [COCO website](https://cocodataset.org/#download). For simplicity, we have included this file as part of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation dataset\n",
    "dataset = CocoDataset(shuffle=True)\n",
    "# Split the dataset into calibration and test subsets\n",
    "calib_dataset, test_dataset = dataset.split(test_size=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688cc407",
   "metadata": {},
   "source": [
    "### üîÆ Prediction Models <a class=\"anchor\" id=\"cr-pm\"></a>\n",
    "\n",
    "\n",
    "We are working with an object detection model that is already in production and accessible only through API requests (i.e., we don't have direct access to the model instance). Let's create an instance of the API, which we will use later to query the model and obtain bounding box predictions for images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the API\n",
    "object_detection_api = ObjectDetectionAPI(min_iou=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4cc26",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Conformal Prediction <a class=\"anchor\" id=\"ob-cp\"></a>\n",
    "\n",
    "The figure below summarizes our scenario: \n",
    "\n",
    "<div align=center>\n",
    "<img src=\"assets/object_detection_demo.svg\" width=\"800\"> </img>\n",
    "</div>\n",
    "\n",
    "From our perspective, the predictions served through the API are generated by an unknown model that is not directly accessible. However, we can still apply conformal prediction techniques to it!\n",
    "\n",
    "Although we don't have a model object to wrap, we can create a proxy using *puncc* using [`IdPredictor`](https://deel-ai.github.io/puncc/prediction.html#prediction.IdPredictor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27380c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deel.puncc.api.prediction import IdPredictor\n",
    "\n",
    "# Create the proxy of object detection model\n",
    "api_model = ...  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b2841d",
   "metadata": {},
   "source": [
    "Now we are ready to perform conformal object detection on COCO. The following code snippet is the template we will follow to implement our conformal object detector !\n",
    "\n",
    "<div align=center>\n",
    "<img src=\"assets/workflow_object_detection.svg\" width=\"800\"> </img>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e89575",
   "metadata": {},
   "source": [
    "#### 1. Instantiation\n",
    "\n",
    "We define an instance of the conformal predictor `SplitBoxWise`. Make sure the argument `train` is set to False, as the model is already trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deel.puncc.object_detection import SplitBoxWise\n",
    "\n",
    "# Instantiate conformal predictor\n",
    "api_cp = SplitBoxWise(..., ...)  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552f7aa",
   "metadata": {},
   "source": [
    "#### 2. Calibration\n",
    "\n",
    "Retrieve predictions and labels for 150 instances (or more up to 247, though this may slow down the process) of the calibration data using the model's API. This data will be used to calibrate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63346397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get calibration data through API\n",
    "y_calib_api, y_calib_coco, calib_images, calib_labels = object_detection_api.query(\n",
    "    calib_dataset, n_instances=...  # TODO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58589a",
   "metadata": {},
   "source": [
    "Now we can fit our conformal predictor. The non-conformity scores are computed and stored within the conformal prediction object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit conformal predictor\n",
    "api_cp.fit(..., ...)  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d743385c",
   "metadata": {},
   "source": [
    "#### 3. Conformal Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325dab96",
   "metadata": {},
   "source": [
    "We first choose an new image and send a request to the API to get the point prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8738bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an image from the test dataset\n",
    "image, bboxes, classes = test_dataset[8]\n",
    "\n",
    "# Predict on the image\n",
    "y_new_api = object_detection_api.predict_from_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d7c92",
   "metadata": {},
   "source": [
    "Finally, we can infer the uncertainty of the model on an example using our conformal predictor. We have to set a level of risk $\\alpha$ that is acceptable for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cf4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the coverage target 1-alpha\n",
    "alpha = 0.3\n",
    "\n",
    "# Inference + UQ\n",
    "y_pred_new, box_inner, box_outer = api_cp.predict(..., ...)  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c86b75e",
   "metadata": {},
   "source": [
    "Let's visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25715d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deel.puncc.plotting import draw_bounding_box\n",
    "\n",
    "image_with_bbox = image.copy()\n",
    "\n",
    "for i in range(min(len(bboxes), len(y_pred_new))):\n",
    "    try:\n",
    "        image_with_bbox = draw_bounding_box(\n",
    "            image=image_with_bbox,\n",
    "            box=y_pred_new[i],\n",
    "            legend=\"Predictions\",\n",
    "            color=\"blue\",\n",
    "        )\n",
    "        image_with_bbox = draw_bounding_box(\n",
    "            image=image_with_bbox,\n",
    "            box=bboxes[i],\n",
    "            label=classes[i],\n",
    "            legend=\"Truth\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "        image_with_bbox = draw_bounding_box(\n",
    "            image=image_with_bbox,\n",
    "            box=box_outer[i],\n",
    "            legend=\"Conformalized Outer Box\",\n",
    "            color=\"orange\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not display bbox {i}\")\n",
    "        continue\n",
    "\n",
    "_ = draw_bounding_box(image=image_with_bbox, show=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "punc-user-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
